# VoiceLinkVR Server 性能优化分析

## 当前处理流程分析

### 音频翻译完整流程 (以 `/api/func/multitranslateToOtherLanguage` 为例)

```
客户端发送音频 -> 接收音频 -> [OPUS解码] -> 语音识别(ASR) -> 文本过滤 -> 翻译 -> 返回结果
```

### 各阶段耗时分析

| 阶段 | 当前实现 | 预估耗时 | 优化潜力 |
|------|----------|----------|----------|
| 1. 音频接收 | `await file.read()` | 10-50ms | 低 |
| 2. OPUS解码 | 同步解码 | 20-100ms | 中 |
| 3. 语音识别(ASR) | Whisper/SenseVoice HTTP调用 | 500-2000ms | 高 |
| 4. 文本过滤 | 内存字典匹配 | <1ms | 无 |
| 5. 翻译 | 串行多语言翻译 | 300-1500ms/语言 | 高 |
| 6. 响应返回 | JSON序列化 | <5ms | 无 |

**总耗时估算**: 1-4秒 (取决于音频长度和翻译语言数量)

---

## 优化方案

### 方案一: 并行翻译 (推荐优先实施)

**问题**: 当前多语言翻译是串行执行的

```python
# 当前代码 (src/routers/api.py:224-234)
transText = do_translate(stext, from_=translate_source_lang, to=targetLanguage)
if targetLanguage2 != "none":
    transText2 = do_translate(stext, from_=translate_source_lang, to=targetLanguage2)
if targetLanguage3 != "none":
    transText3 = do_translate(stext, from_=translate_source_lang, to=targetLanguage3)
```

**优化方案**: 使用 `asyncio.gather` 并行执行翻译

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# 创建线程池执行器
executor = ThreadPoolExecutor(max_workers=10)

async def async_do_translate(text: str, from_: str, to: str) -> str:
    """将同步翻译函数包装为异步"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(executor, do_translate, text, from_, to)

# 优化后的翻译逻辑
async def parallel_translate(text: str, source_lang: str, targets: list) -> dict:
    tasks = []
    for target in targets:
        if target != "none":
            tasks.append(async_do_translate(text, source_lang, target))
        else:
            tasks.append(asyncio.coroutine(lambda: "")())

    results = await asyncio.gather(*tasks, return_exceptions=True)
    return {
        'translatedText': results[0] if not isinstance(results[0], Exception) else "",
        'translatedText2': results[1] if len(results) > 1 and not isinstance(results[1], Exception) else "",
        'translatedText3': results[2] if len(results) > 2 and not isinstance(results[2], Exception) else ""
    }
```

**预期收益**: 3语言翻译从 ~4.5秒 降至 ~1.5秒 (节省约67%)

---

### 方案二: ASR与翻译流水线并行

**问题**: 当前流程是完全串行的: ASR完成 -> 翻译开始

**优化方案**: 对于需要英文翻译的场景，可以同时启动:
1. 中文ASR (SenseVoice)
2. 英文翻译ASR (Whisper translations)

```python
async def parallel_asr_and_translate(audio_file: bytes, source_lang: str, target_lang: str):
    """并行执行ASR和翻译"""

    async def get_chinese_text():
        async with httpx.AsyncClient() as client:
            files = {'file': ('audio.wav', audio_file, 'audio/wav')}
            response = await client.post(SENSEVOICE_URL, files=files)
            return response.json().get('text', '')

    async def get_english_translation():
        # 使用线程池执行同步的Whisper调用
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            executor,
            lambda: whisperclient.audio.translations.create(
                model=settings.WHISPER_MODEL,
                file=audio_file
            ).text
        )

    # 如果目标语言包含英文，并行执行
    if target_lang == 'en' or source_lang == 'zh':
        chinese_text, english_text = await asyncio.gather(
            get_chinese_text(),
            get_english_translation()
        )
        return chinese_text, english_text
    else:
        chinese_text = await get_chinese_text()
        return chinese_text, None
```

**预期收益**: ASR阶段节省 500-1000ms

---

### 方案三: 连接池优化

**问题**: 每次请求都创建新的 HTTP 客户端

```python
# 当前代码 (src/routers/api.py:176-181)
async with httpx.AsyncClient() as client:
    files = {'file': ('audio.wav', audio_file, 'audio/wav')}
    response = await client.post(SENSEVOICE_URL, files=files)
```

**优化方案**: 使用全局连接池

```python
# 在 src/core/services.py 中添加
from httpx import AsyncClient, Limits

# 创建全局异步HTTP客户端，配置连接池
http_client = AsyncClient(
    limits=Limits(
        max_keepalive_connections=20,
        max_connections=100,
        keepalive_expiry=30.0
    ),
    timeout=30.0
)

# 在应用关闭时清理
async def cleanup_http_client():
    await http_client.aclose()
```

**预期收益**: 每次请求节省 20-50ms 的连接建立时间

---

### 方案四: Whisper客户端异步化

**问题**: OpenAI客户端是同步的，会阻塞事件循环

```python
# 当前代码 (src/routers/api.py:63)
res = whisperclient.audio.transcriptions.create(model=settings.WHISPER_MODEL, file=audio_file, language='zh')
```

**优化方案**: 使用 OpenAI 的异步客户端

```python
from openai import AsyncOpenAI

# 创建异步客户端
async_whisperclient = AsyncOpenAI(
    api_key=settings.WHISPER_APIKEY,
    base_url=WHISPER_URL
)

# 使用异步调用
async def async_transcribe(audio_file: bytes, language: str = 'zh') -> str:
    res = await async_whisperclient.audio.transcriptions.create(
        model=settings.WHISPER_MODEL,
        file=audio_file,
        language=language
    )
    return res.text
```

**预期收益**: 提高并发处理能力，避免阻塞其他请求

---

### 方案五: 音频预处理优化

**问题**: OPUS解码是同步且CPU密集型操作

```python
# 当前代码 (src/routers/api.py:170-171)
if file.content_type == 'audio/opus':
    audio_file = packaged_opus_stream_to_wav_bytes(audio_file, 16000)
```

**优化方案**: 使用进程池处理CPU密集型任务

```python
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

# 创建进程池 (CPU密集型任务)
process_executor = ProcessPoolExecutor(max_workers=multiprocessing.cpu_count())

async def async_decode_opus(opus_data: bytes, sample_rate: int) -> bytes:
    """异步OPUS解码"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        process_executor,
        packaged_opus_stream_to_wav_bytes,
        opus_data,
        sample_rate
    )
```

**预期收益**: 避免阻塞事件循环，提高并发能力

---

### 方案六: 翻译结果缓存

**问题**: 相同文本重复翻译

**优化方案**: 添加LRU缓存

```python
from functools import lru_cache
import hashlib

# 简单的内存缓存
translation_cache = {}
CACHE_MAX_SIZE = 10000

def get_cache_key(text: str, from_lang: str, to_lang: str) -> str:
    return hashlib.md5(f"{text}:{from_lang}:{to_lang}".encode()).hexdigest()

def cached_translate(text: str, from_: str, to: str) -> str:
    cache_key = get_cache_key(text, from_, to)

    if cache_key in translation_cache:
        return translation_cache[cache_key]

    result = do_translate(text, from_, to)

    # 简单的缓存淘汰策略
    if len(translation_cache) >= CACHE_MAX_SIZE:
        # 删除最早的1000条
        keys_to_delete = list(translation_cache.keys())[:1000]
        for key in keys_to_delete:
            del translation_cache[key]

    translation_cache[cache_key] = result
    return result
```

**预期收益**: 重复文本翻译从 ~1.5秒 降至 <1ms

---

### 方案七: 流式响应 (高级优化)

**问题**: 客户端需要等待所有翻译完成才能收到响应

**优化方案**: 使用 Server-Sent Events (SSE) 流式返回结果

```python
from fastapi.responses import StreamingResponse
import json

async def stream_translation_results(text: str, targets: list):
    """流式返回翻译结果"""

    # 首先返回原文
    yield f"data: {json.dumps({'type': 'text', 'content': text})}\n\n"

    # 并行启动所有翻译任务
    async def translate_and_yield(target: str, index: int):
        result = await async_do_translate(text, 'zh', target)
        return {'type': f'translation{index}', 'content': result, 'target': target}

    tasks = [translate_and_yield(t, i) for i, t in enumerate(targets) if t != 'none']

    # 使用 as_completed 按完成顺序返回
    for coro in asyncio.as_completed(tasks):
        result = await coro
        yield f"data: {json.dumps(result)}\n\n"

    yield "data: {\"type\": \"done\"}\n\n"

@router.post("/func/streamTranslate")
async def stream_translate(file: UploadFile = File(...), ...):
    # ... 音频处理逻辑 ...
    return StreamingResponse(
        stream_translation_results(text, [targetLanguage, targetLanguage2, targetLanguage3]),
        media_type="text/event-stream"
    )
```

**预期收益**: 用户可以更快看到部分结果，提升体验

---

## 优化优先级建议

| 优先级 | 方案 | 实施难度 | 预期收益 | 风险 |
|--------|------|----------|----------|------|
| P0 | 方案一: 并行翻译 | 低 | 高 (节省67%翻译时间) | 低 |
| P0 | 方案三: 连接池优化 | 低 | 中 (节省20-50ms/请求) | 低 |
| P1 | 方案四: Whisper异步化 | 中 | 高 (提升并发能力) | 低 |
| P1 | 方案二: ASR并行 | 中 | 中 (节省500-1000ms) | 中 |
| P2 | 方案五: OPUS进程池 | 中 | 中 (提升并发能力) | 低 |
| P2 | 方案六: 翻译缓存 | 低 | 中 (重复请求加速) | 低 |
| P3 | 方案七: 流式响应 | 高 | 中 (提升用户体验) | 中 |

---

## 快速实施方案 (方案一完整代码)

以下是可以直接应用的并行翻译优化代码:

### 1. 修改 `src/core/services.py`

在文件末尾添加:

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

# 翻译线程池
_translate_executor = ThreadPoolExecutor(max_workers=10)

async def async_do_translate(text: str, from_: str, to: str) -> str:
    """异步翻译包装函数"""
    if not text or to == "none":
        return ""
    loop = asyncio.get_event_loop()
    try:
        return await loop.run_in_executor(_translate_executor, do_translate, text, from_, to)
    except Exception as e:
        logger.error(f"[ASYNC-TRANSLATE] 翻译失败: {e}")
        return text

async def parallel_translate(text: str, from_lang: str, targets: list) -> tuple:
    """并行执行多语言翻译

    Args:
        text: 要翻译的文本
        from_lang: 源语言
        targets: 目标语言列表 [target1, target2, target3]

    Returns:
        tuple: (翻译结果1, 翻译结果2, 翻译结果3)
    """
    tasks = []
    for target in targets:
        if target and target != "none":
            tasks.append(async_do_translate(text, from_lang, target))
        else:
            # 创建一个立即返回空字符串的协程
            async def empty_result():
                return ""
            tasks.append(empty_result())

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # 处理异常情况
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"[PARALLEL-TRANSLATE] 翻译任务{i}失败: {result}")
            processed_results.append("")
        else:
            processed_results.append(result)

    return tuple(processed_results)
```

### 2. 修改 `src/routers/api.py`

在导入部分添加:
```python
from core.services import parallel_translate
```

修改 `multitranslate_to_other_language` 函数中的翻译部分:

```python
# 替换原有的串行翻译代码
if settings.ENABLE_WEB_TRANSLATORS:
    translate_source_lang = 'auto' if sourceLanguage == 'zh' else sourceLanguage
    logger.info(f"[MULTITRANSLATE] 使用并行网页翻译服务 - 源语言: {translate_source_lang}")

    # 并行翻译
    transText, transText2, transText3 = await parallel_translate(
        stext,
        translate_source_lang,
        [targetLanguage, targetLanguage2, targetLanguage3]
    )

    logger.info(f"[MULTITRANSLATE] 并行翻译完成")
```

---

## 性能监控建议

建议添加以下监控指标:

```python
import time
from dataclasses import dataclass
from typing import Optional

@dataclass
class PerformanceMetrics:
    request_id: str
    audio_receive_ms: float = 0
    opus_decode_ms: float = 0
    asr_ms: float = 0
    filter_ms: float = 0
    translate_ms: float = 0
    total_ms: float = 0

def log_performance(metrics: PerformanceMetrics):
    logger.info(
        f"[PERF] request_id={metrics.request_id} "
        f"audio={metrics.audio_receive_ms:.1f}ms "
        f"opus={metrics.opus_decode_ms:.1f}ms "
        f"asr={metrics.asr_ms:.1f}ms "
        f"filter={metrics.filter_ms:.1f}ms "
        f"translate={metrics.translate_ms:.1f}ms "
        f"total={metrics.total_ms:.1f}ms"
    )
```

---

## 总结

通过实施上述优化方案，预计可以将音频翻译的总耗时从 **1-4秒** 降低到 **0.5-1.5秒**，主要收益来自:

1. **并行翻译**: 节省约 67% 的翻译时间
2. **连接池复用**: 节省约 20-50ms/请求
3. **ASR并行**: 节省约 500-1000ms (特定场景)

建议按照优先级顺序逐步实施，每次实施后进行性能测试验证效果。
